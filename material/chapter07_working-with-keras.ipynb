{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: a deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design of the Keras API is guided by the principle of **progressive disclosure of complexity**: make it easy to get started, yet make it possible to handle high-complexity use cases, only requiring incremental learning at each step. Simple use cases should be easy and approachable, and arbitrarily advanced workflows should be possible: no matter how niche and complex the thing you want to do, there should be a clear path to it. A path that builds upon the various thing you’ve learned from simpler workflows. This means that you can grow from beginner to expert and still use the same tools—only in different ways.\n",
    "\n",
    "As such, there’s not a single \"true\" way of using Keras. Rather, Keras offers a spectrum of workflows, from the very simple to the very flexible. There are different ways to build Keras models, and different ways to train them, answering different needs. Because all these workflows are based on shared APIs, such as `Layer` and `Model`, components from any workflow can be used in any other workflow: they can all talk to each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three APIs for building models in Keras:\n",
    "\n",
    "- The **Sequential model**, the most approachable API—it’s basically a Python list. As such, it’s limited to **simple stacks of layers**.\n",
    "- The **Functional API**, which focuses on **graph-like model architectures**. It represents a nice mid-point between usability and flexibility, and as such, it’s the most commonly-used model-building API.\n",
    "- **Model subclassing**, a low-level option where you write everything yourself from scratch. This is ideal if you want full control over every little thing. However, you won’t get access to many built-in Keras features, and you will be more at risk of making mistakes.\n",
    "\n",
    "![](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/progressive_disclosure_of_complexity_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The Sequential class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it’s possible to build the same model incrementally, via the `add()` method, similar to the `append()` method of a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve seen in chapter 4 that layers only get built (which is to say, create their weights) when they are called for the first time. That’s because the shape of the layers' weights depend on the shape of their input: **until the input shape is known, they can’t be created**.\n",
    "\n",
    "As such, the Sequential model above does not have any weights until you actually call it on some data, or call its `build()` method with an input shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.27145636, -0.13949892,  0.06876865,  0.16211155,  0.16421267,\n",
       "         -0.12415816, -0.18592869, -0.25711367, -0.12244853,  0.26597273,\n",
       "         -0.24261408, -0.23034295, -0.2550316 ,  0.19015709,  0.2923563 ,\n",
       "          0.21959764, -0.2598512 ,  0.03888521, -0.00825611, -0.24606907,\n",
       "          0.24059331,  0.08045286, -0.13243103,  0.1336866 ,  0.2381221 ,\n",
       "         -0.06626058,  0.14362139, -0.17734231, -0.01623389, -0.06820379,\n",
       "         -0.2127708 , -0.29538128, -0.28938666,  0.02677906, -0.15015887,\n",
       "         -0.2812689 ,  0.27614492, -0.14703463,  0.22619879, -0.29392764,\n",
       "         -0.24272838, -0.06267615, -0.24999204, -0.2095384 ,  0.0046418 ,\n",
       "         -0.05937141,  0.1997489 , -0.17595418, -0.28289235,  0.2511968 ,\n",
       "          0.21830106,  0.1303862 ,  0.19777128,  0.18978602, -0.18642356,\n",
       "          0.11958215,  0.17256802,  0.15803283, -0.1232031 , -0.16810517,\n",
       "         -0.1517965 , -0.17064722, -0.214427  ,  0.21804047],\n",
       "        [ 0.00236073,  0.22744828, -0.07092148, -0.17371808, -0.19965065,\n",
       "         -0.15588386, -0.01345769, -0.16568714, -0.17945006,  0.10899639,\n",
       "          0.17614603, -0.16645834, -0.2623373 , -0.2787255 , -0.29273564,\n",
       "          0.10020432, -0.09830819, -0.1793877 ,  0.10003144,  0.11211741,\n",
       "         -0.11303602,  0.2113254 ,  0.2549153 ,  0.22282135, -0.24649858,\n",
       "          0.04132423,  0.00632995, -0.10734792, -0.20263605,  0.24281287,\n",
       "          0.2513736 ,  0.26384377, -0.14361317, -0.13523391,  0.08648413,\n",
       "          0.20041016, -0.22294003, -0.28658906,  0.23472846, -0.0834516 ,\n",
       "          0.2850805 ,  0.10659391,  0.12582874,  0.06166202,  0.02419963,\n",
       "          0.23794031, -0.21266827,  0.08549464,  0.08303857,  0.13492313,\n",
       "          0.07868215, -0.16061284,  0.18445343, -0.00380731,  0.03815076,\n",
       "         -0.13614923, -0.14460526,  0.10819182, -0.26558483, -0.07263154,\n",
       "          0.20851249,  0.11057547,  0.09492183,  0.0313592 ],\n",
       "        [ 0.09672877, -0.03010848,  0.08749884, -0.11074527, -0.16218711,\n",
       "          0.19374788,  0.18112236,  0.06530902, -0.2209072 , -0.07613792,\n",
       "         -0.29895335, -0.00876588,  0.2351774 ,  0.28437728, -0.15035322,\n",
       "          0.11191314,  0.00170541, -0.27819505,  0.07888043,  0.20818424,\n",
       "          0.04549539,  0.26099843, -0.20124406, -0.01914579,  0.07743359,\n",
       "          0.07065493, -0.11196852,  0.07440102, -0.19122937,  0.01840779,\n",
       "         -0.25731972,  0.02189973, -0.20409766,  0.13944691, -0.20182483,\n",
       "          0.16228521,  0.0557541 ,  0.07527795,  0.07582712,  0.06306869,\n",
       "          0.04271457,  0.29587764, -0.15373181,  0.26527345, -0.2394255 ,\n",
       "         -0.26403272, -0.21697453,  0.22875023,  0.16063967,  0.29314834,\n",
       "          0.10842049, -0.01578626, -0.02634695, -0.05900654,  0.28000104,\n",
       "          0.1770049 ,  0.13312745, -0.23272875,  0.18317461, -0.285688  ,\n",
       "          0.2894367 ,  0.01350629, -0.23673305,  0.28768563]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.03950566, -0.11296456, -0.2448648 ,  0.20489267, -0.1900139 ,\n",
       "         -0.17934608, -0.03477454,  0.19664007,  0.12341425,  0.12227574],\n",
       "        [ 0.02572352,  0.04900295, -0.0777427 ,  0.02703458,  0.01029763,\n",
       "          0.10717207,  0.09832793, -0.19362432,  0.22368303, -0.0552877 ],\n",
       "        [-0.28272504, -0.09437029, -0.18121663,  0.1873517 , -0.21628582,\n",
       "         -0.16219296, -0.19200107, -0.27743378,  0.01525339,  0.09221929],\n",
       "        [ 0.18354592,  0.06463289, -0.05051605, -0.14590338,  0.05117911,\n",
       "          0.19855985, -0.13447745, -0.2746979 ,  0.01075953,  0.02100095],\n",
       "        [-0.22985223, -0.09369099,  0.23132673,  0.17982903, -0.10645495,\n",
       "          0.2605203 , -0.1098384 ,  0.12253836, -0.11421609,  0.22320804],\n",
       "        [-0.1606199 , -0.1041732 , -0.16937706,  0.27274296, -0.24774425,\n",
       "         -0.10413416,  0.27235773,  0.12246624, -0.14440432, -0.22470881],\n",
       "        [ 0.2543606 ,  0.2736841 , -0.00114727, -0.20629573, -0.0868517 ,\n",
       "         -0.25900447, -0.0238032 ,  0.22261158,  0.24452898,  0.14832473],\n",
       "        [-0.01995471, -0.06850421,  0.17205235,  0.01590294,  0.08598238,\n",
       "         -0.10575826, -0.01304427,  0.23837438,  0.23769519, -0.22456536],\n",
       "        [ 0.26643655, -0.08732687,  0.18828368, -0.0494248 ,  0.01320165,\n",
       "         -0.0605635 ,  0.113552  , -0.18694308,  0.00479433,  0.01564342],\n",
       "        [-0.0738631 ,  0.13933131,  0.19017562, -0.11450164,  0.19278222,\n",
       "          0.08424905, -0.27975503, -0.19968158,  0.15797588,  0.1372835 ],\n",
       "        [-0.1252814 , -0.11304033, -0.13625011,  0.26598528,  0.08209655,\n",
       "         -0.2369564 ,  0.12224254, -0.00925383, -0.04405119,  0.08008888],\n",
       "        [-0.17115228, -0.06083451, -0.02966577, -0.0637566 ,  0.19725746,\n",
       "         -0.08888397, -0.10288467, -0.25489053,  0.24623677,  0.08611917],\n",
       "        [ 0.21721992, -0.19769867,  0.08209437, -0.08875023, -0.05405043,\n",
       "          0.13714835, -0.10894397, -0.12534915, -0.23848629,  0.2014752 ],\n",
       "        [-0.04502322,  0.08281496, -0.01844418, -0.09867506, -0.09281963,\n",
       "         -0.09793583, -0.19715685,  0.05309454, -0.12337168, -0.14613469],\n",
       "        [-0.07084055, -0.10819413,  0.02454847,  0.05215776,  0.13930476,\n",
       "         -0.03533463,  0.26797566, -0.01665142,  0.02875373,  0.0461129 ],\n",
       "        [-0.05142875,  0.00067779, -0.15435565,  0.20057806, -0.03681698,\n",
       "          0.23456964, -0.13381682,  0.08399794,  0.16823217,  0.04271439],\n",
       "        [ 0.28255913, -0.22036153,  0.22156695,  0.22637567,  0.05988216,\n",
       "          0.1594662 ,  0.13109088,  0.10444117,  0.24283049, -0.08218135],\n",
       "        [-0.2056905 ,  0.12765583, -0.17488495, -0.10826433, -0.18739039,\n",
       "          0.09725088, -0.01815403,  0.08384395,  0.04108313,  0.09815177],\n",
       "        [-0.17363784, -0.2636394 ,  0.2834786 , -0.02188274, -0.02527598,\n",
       "         -0.17263463, -0.10224603, -0.16311109,  0.11950505, -0.17177597],\n",
       "        [-0.26214734, -0.14650618, -0.25261387,  0.1682427 , -0.12581182,\n",
       "         -0.1203274 ,  0.03580415,  0.04127851,  0.118117  , -0.12048469],\n",
       "        [-0.02191216,  0.16005751, -0.04329088,  0.2644318 , -0.20714828,\n",
       "         -0.05430175, -0.02668324,  0.05303901, -0.16614634, -0.25587207],\n",
       "        [-0.11521494,  0.2136839 ,  0.07258835, -0.19890797,  0.17889747,\n",
       "         -0.18749705, -0.14796497,  0.16443866, -0.17994764, -0.17526567],\n",
       "        [-0.19981295,  0.22963706,  0.2615188 ,  0.08330417,  0.07649067,\n",
       "         -0.07655579, -0.2785959 , -0.12529607, -0.2605326 ,  0.14514118],\n",
       "        [-0.07951826, -0.15215339,  0.18148819,  0.15451837, -0.02359721,\n",
       "          0.22757426, -0.01452446,  0.1735444 ,  0.1705279 ,  0.1456205 ],\n",
       "        [-0.2744176 ,  0.2663931 , -0.0462216 ,  0.02788943,  0.10049328,\n",
       "         -0.15745294,  0.03110337, -0.17744689, -0.08875912, -0.0135808 ],\n",
       "        [ 0.26292786,  0.04268709,  0.20098498, -0.12076698,  0.14961067,\n",
       "          0.18851465,  0.15845701,  0.19324976,  0.19106698, -0.26581442],\n",
       "        [-0.1734254 , -0.12222551,  0.06284267,  0.21049705, -0.2676075 ,\n",
       "         -0.08017936, -0.22890836,  0.07832804, -0.2148543 ,  0.28454062],\n",
       "        [-0.14201905, -0.13073786, -0.22026092,  0.19865876,  0.23619434,\n",
       "         -0.07328089, -0.1862593 ,  0.2411662 ,  0.01032722, -0.1352541 ],\n",
       "        [-0.24726373,  0.18181765, -0.23056696, -0.03956276, -0.09771293,\n",
       "         -0.23338857, -0.25218156, -0.07948487,  0.22609428, -0.22737196],\n",
       "        [-0.2489205 ,  0.10430089, -0.09835042, -0.10066523,  0.04619411,\n",
       "          0.10543287, -0.21823865, -0.16972212, -0.00799564, -0.20581216],\n",
       "        [ 0.22613516,  0.28131273, -0.24013253,  0.09134719,  0.00527701,\n",
       "         -0.07724404, -0.23126921, -0.09264176,  0.12360251, -0.11781754],\n",
       "        [-0.1157808 , -0.1786224 , -0.23822275,  0.0850614 , -0.06141618,\n",
       "         -0.14932092,  0.11106122,  0.17631382, -0.22726062,  0.08315074],\n",
       "        [-0.2350904 , -0.01733336,  0.12552273, -0.0055936 , -0.19550334,\n",
       "         -0.04646945, -0.01338461,  0.21353951, -0.27369845, -0.13331899],\n",
       "        [-0.123952  ,  0.21204743,  0.06973925, -0.13397887,  0.00271487,\n",
       "         -0.18430993, -0.12131552,  0.14704868,  0.2761056 , -0.2346727 ],\n",
       "        [ 0.23633835,  0.24060306,  0.1642088 , -0.22685608,  0.18902102,\n",
       "          0.20170262, -0.096091  , -0.20472601, -0.1338067 , -0.073561  ],\n",
       "        [-0.28067642, -0.2065588 , -0.15878221, -0.13455233,  0.10963115,\n",
       "          0.25501373,  0.21873125,  0.27785924, -0.01507917,  0.24341974],\n",
       "        [-0.15374552, -0.10782237, -0.22785383,  0.2091367 ,  0.05822113,\n",
       "         -0.13014661, -0.26195478, -0.20971233, -0.06347825, -0.11461331],\n",
       "        [-0.25007236,  0.11478922,  0.2449579 ,  0.01719269, -0.0934878 ,\n",
       "         -0.19587198,  0.18062857, -0.13314098,  0.08998588, -0.22595125],\n",
       "        [ 0.19448468, -0.18772781,  0.05452904, -0.06908901,  0.28149328,\n",
       "         -0.21448478,  0.13170254,  0.1805934 , -0.23266391,  0.06415212],\n",
       "        [ 0.07177803,  0.15810046, -0.10778251,  0.0858179 ,  0.13656524,\n",
       "          0.16084144,  0.01788571, -0.06386209, -0.21188402, -0.1281692 ],\n",
       "        [ 0.21567735, -0.09134705,  0.26819327,  0.08646616, -0.28257596,\n",
       "          0.03276584, -0.2340754 , -0.13931407, -0.02184692, -0.23733027],\n",
       "        [-0.07897373, -0.211705  ,  0.2149215 , -0.25570446,  0.22935048,\n",
       "          0.13006717,  0.16018888, -0.11084004,  0.16013435, -0.07188597],\n",
       "        [-0.27419853, -0.02432093, -0.28264922,  0.23273656,  0.24083129,\n",
       "         -0.00945389,  0.23796424,  0.23812863,  0.15553448,  0.24911919],\n",
       "        [ 0.16033551,  0.2551709 ,  0.12982821,  0.00241679,  0.00465286,\n",
       "          0.16116783,  0.20327705,  0.2203385 ,  0.13604012,  0.00849164],\n",
       "        [-0.09104256, -0.17388603, -0.17010726,  0.06505361,  0.049247  ,\n",
       "         -0.21217847, -0.2163099 , -0.12020947, -0.25032628,  0.15123147],\n",
       "        [ 0.25437412,  0.19740403,  0.06835058,  0.25651798, -0.22584507,\n",
       "          0.13137302, -0.03610565, -0.28435594, -0.16818485, -0.17402059],\n",
       "        [ 0.1534122 , -0.1865242 ,  0.06545234,  0.20876709,  0.14718825,\n",
       "         -0.01003426,  0.18468285, -0.01453015, -0.19535664,  0.06002086],\n",
       "        [-0.00835055,  0.01604185,  0.09822387,  0.27504906,  0.00809884,\n",
       "         -0.2554853 , -0.13002326, -0.04841679, -0.26452404,  0.17653853],\n",
       "        [-0.04622118, -0.1600216 , -0.07518579,  0.13336238,  0.26120242,\n",
       "         -0.05299081, -0.2578682 , -0.27587885, -0.27088445,  0.03916976],\n",
       "        [ 0.1484816 ,  0.17586535,  0.07049337, -0.24202907,  0.11309952,\n",
       "         -0.05711596,  0.06063017, -0.24312773, -0.23551668,  0.06577739],\n",
       "        [-0.07645632,  0.02560028, -0.17946611, -0.23382285,  0.22466686,\n",
       "         -0.0344258 , -0.27857348, -0.20617944, -0.04082699,  0.00335753],\n",
       "        [-0.14419693, -0.19968212, -0.13608527,  0.13930172, -0.11445418,\n",
       "          0.07036668,  0.10919705, -0.23497832,  0.08604884, -0.0539754 ],\n",
       "        [-0.22073784, -0.05793965, -0.16705292,  0.0318177 , -0.05777237,\n",
       "         -0.20378065, -0.12205756, -0.19376159, -0.20712146, -0.14104593],\n",
       "        [-0.20384595, -0.20134126,  0.22273359,  0.07619599,  0.17955953,\n",
       "          0.20893383, -0.13589911,  0.16980109,  0.1129002 ,  0.0577015 ],\n",
       "        [ 0.2796704 , -0.03729595, -0.08394293, -0.06007205, -0.1766538 ,\n",
       "         -0.11552812,  0.07674819,  0.05444738, -0.149014  , -0.24338767],\n",
       "        [ 0.2566782 , -0.26465935, -0.08668226,  0.02452865, -0.20317243,\n",
       "          0.04432261,  0.09958151,  0.02885374,  0.02399409, -0.03699064],\n",
       "        [-0.05932547, -0.06589849,  0.20929745, -0.14512843, -0.06578518,\n",
       "          0.17733377, -0.05131952, -0.2403996 , -0.22749165, -0.07914589],\n",
       "        [-0.18648306, -0.02753982, -0.03221193, -0.18008085,  0.23435363,\n",
       "          0.0992471 , -0.1701254 , -0.18677539, -0.05076358, -0.05441342],\n",
       "        [ 0.04991102, -0.24477641, -0.1633341 ,  0.04373184, -0.27628177,\n",
       "         -0.26411822, -0.11474115,  0.12424907, -0.27536973, -0.17247856],\n",
       "        [-0.19319043,  0.11690062, -0.2357245 ,  0.24049696,  0.21438193,\n",
       "         -0.13947652,  0.26360974, -0.09968831,  0.22996739,  0.06544256],\n",
       "        [-0.20807144,  0.17059723, -0.02861029,  0.07022542, -0.2529282 ,\n",
       "          0.12387276,  0.11669385,  0.27166578, -0.00056714, -0.09295106],\n",
       "        [-0.09900039,  0.05920395,  0.11602011, -0.08302073,  0.07817182,\n",
       "          0.04922235,  0.0058468 ,  0.14311123,  0.02365175, -0.00607288],\n",
       "        [-0.12839453, -0.22667664,  0.27957657,  0.231177  , -0.15120973,\n",
       "         -0.2062975 , -0.1704478 , -0.14729634,  0.04588732,  0.00367272],\n",
       "        [-0.24676196, -0.27677476, -0.20727423, -0.0305976 , -0.2244526 ,\n",
       "         -0.06175862, -0.09109369, -0.27775592, -0.07988486, -0.13394514]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is built, you can display its contents via the `summary()` method, which comes handy for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see your model happens to be named \"sequential_1\". You can actually give names to everything in Keras—every model, every layer. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a Sequential model incrementally, it’s useful to be able to print a summary of what the current model looks like after you add each layer. But you can’t print a summary until the model is built! There’s actually a way to have your Sequential get built on the fly: just **declare the shape of the model’s inputs in advance**. You can do this via the Input class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# With explicit InputLayer.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(3,)),\n",
    "  keras.layers.Dense(64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without InputLayer and let the first layer to have the input_shape.\n",
    "# Keras will add a input for the model behind the scene.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(64, input_shape=(3,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is easy to use, but its applicability is extremely limited: it can **only express models with a single input and a single output**, applying one layer after the other in a sequential fashion. In practice, it’s pretty common to encounter models with **multiple inputs** (say, an image and its metadata), **multiple outputs** (different things you want to predict about the data), or a **non-linear topology**.\n",
    "\n",
    "In such cases, you’d build your model using the **Functional API**. This is what most Keras models you’ll encounter in the wild use. It’s fun and powerful—it feels like playing with LEGO bricks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with something simple: the two-layer stack of layers we used in the section above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two Dense layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")  # no longer a layer but a tensor!\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by declaring an `Input` (note that you can also give names to these input objects, like everything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "#inputs = tf.random.normal([3, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inputs object holds information about the `shape` and `dtype` of the data that the model will process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call such an object a __symbolic tensor__. It doesn’t contain any actual data, but it encodes the specifications of the actual tensors of data that the model will see when you use it. It stands for future tensors of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created a layer and called it on the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Keras layers can be called **both on real tensors of data, or on these symbolic tensors**. In the latter case, they return a new symbolic tensor, with updated shape and dtype information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the final outputs, we instantiated the model by specifying its inputs and outputs in the `Model` constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike this toy model, most deep learning models don’t look like lists—they look like **graphs**. They may, for instance, have multiple inputs or multiple outputs. It’s for this kind of model that the **Functional API** really shines.\n",
    "\n",
    "Let’s say you’re building a system to rank customer support tickets by priority and route them to the appropriate department. Your model has three inputs:\n",
    "\n",
    "- The title of the ticket (text input)\n",
    "- The text body of the ticket (text input)\n",
    "- Any tags added by the user (categorical input, assumed here to be one-hot encoded)\n",
    "\n",
    "We can encode the text inputs as arrays of ones and zeros of size vocabulary_size (see chapter 11 for detailed informations about text encoding techniques).\n",
    "\n",
    "Your model also has two outputs:\n",
    "\n",
    "- The priority score of the ticket, a scalar between 0 and 1 (sigmoid output)\n",
    "- The department that should handle the ticket (a softmax over the set of departments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "# Define model inputs\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "# Combine input features into a single tensor, features, by concatenating them\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "# Apply intermediate layer to recombine input features into richer representations\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "# Define model outputs\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Functional API is a simple, LEGO-like, yet very flexible way to define arbitrary graphs of layers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train your model in much the same way as you would train a `Sequential` model, by calling `fit()` with lists of input and output data. These lists of data should respect the same order as what you passed to the `Model()` constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 37ms/step - loss: 6.4367 - priority_loss: 0.3289 - department_loss: 6.1078 - priority_mean_absolute_error: 0.4927 - department_accuracy: 0.2398\n",
      "40/40 [==============================] - 2s 35ms/step - loss: 3.5988 - priority_loss: 0.3289 - department_loss: 3.2699 - priority_mean_absolute_error: 0.4927 - department_accuracy: 0.2930\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "history = model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [6.436682224273682],\n",
       " 'priority_loss': [0.3289239704608917],\n",
       " 'department_loss': [6.107758045196533],\n",
       " 'priority_mean_absolute_error': [0.4926694333553314],\n",
       " 'department_accuracy': [0.23984375596046448]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don’t want to rely on input order (for instance because you have many inputs or outputs), you can also leverage the names you gave to the `Input` objects and to the output layers, and pass data via dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 37ms/step - loss: 5.6641 - priority_loss: 0.3289 - department_loss: 5.3352 - priority_mean_absolute_error: 0.4927 - department_accuracy: 0.2539\n",
      "40/40 [==============================] - 2s 36ms/step - loss: 3.6681 - priority_loss: 0.3289 - department_loss: 3.3392 - priority_mean_absolute_error: 0.4927 - department_accuracy: 0.1008\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: access to layer connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Functional model is an explicit **graph data structure**. This make it possible to inspect how layers are connected and **reuse previous graph nodes** (which are layer outputs) as part of new models. It also nicely fits the \"mental model\" that most researchers use when thinking about a deep neural network: a graph of layers.\n",
    "\n",
    "This enables two important use cases: **model visualization**, and **feature extraction**. Let’s take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Plotting layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier_with_shapes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"None\" in the tensor shapes represents the **batch size**: this model allows batches of any size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Feature extraction with a Functional model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to layer connectivity also means that you can inspect and reuse individual nodes (layer calls) in the graph. The model property `model.layers` provides the list of layers that make up the model, and for each layer you can query `layer.input` and `layer.output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x22414c92b50>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x22414c92760>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x22414a21f10>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x22414c7f4c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22414c83bb0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22414c99820>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x224138caee0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. layer name: title\n",
      "inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 10000), dtype=tf.float32, name='title'), name='title', description=\"created by layer 'title'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 10000), dtype=tf.float32, name='title'), name='title', description=\"created by layer 'title'\")\n",
      "\n",
      "1. layer name: text_body\n",
      "inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 10000), dtype=tf.float32, name='text_body'), name='text_body', description=\"created by layer 'text_body'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 10000), dtype=tf.float32, name='text_body'), name='text_body', description=\"created by layer 'text_body'\")\n",
      "\n",
      "2. layer name: tags\n",
      "inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='tags'), name='tags', description=\"created by layer 'tags'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='tags'), name='tags', description=\"created by layer 'tags'\")\n",
      "\n",
      "3. layer name: concatenate\n",
      "input 0.: KerasTensor(type_spec=TensorSpec(shape=(None, 10000), dtype=tf.float32, name='title'), name='title', description=\"created by layer 'title'\")\n",
      "input 1.: KerasTensor(type_spec=TensorSpec(shape=(None, 10000), dtype=tf.float32, name='text_body'), name='text_body', description=\"created by layer 'text_body'\")\n",
      "input 2.: KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='tags'), name='tags', description=\"created by layer 'tags'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 20100), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
      "\n",
      "4. layer name: dense_24\n",
      "inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 20100), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_24/Relu:0', description=\"created by layer 'dense_24'\")\n",
      "\n",
      "5. layer name: priority\n",
      "inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_24/Relu:0', description=\"created by layer 'dense_24'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='priority/Sigmoid:0', description=\"created by layer 'priority'\")\n",
      "\n",
      "6. layer name: department\n",
      "inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_24/Relu:0', description=\"created by layer 'dense_24'\")\n",
      "outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name=None), name='department/Softmax:0', description=\"created by layer 'department'\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{i}. layer name:\", layer.name)\n",
    "    \n",
    "    if not isinstance(layer.input, list):\n",
    "        print(\"inputs:\", layer.input)\n",
    "    else:\n",
    "        for i, input_ in enumerate(layer.input):\n",
    "            print(f\"input {i}.: {input_}\")\n",
    "    \n",
    "    if not isinstance(layer.output, list):\n",
    "        print(\"outputs:\", layer.output)\n",
    "    else:\n",
    "         for i, output in enumerate(layer.output):\n",
    "            print(f\"output {i}.: {output}\")\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables you to do **feature extraction**: creating models that reuse intermediate features from another model.\n",
    "\n",
    "Let’s say you want to add another output to the model we defined above—you want to also predict an estimate of how long a given issue ticket will take to resolve, a kind of difficulty rating. You could do this via a classification layer over 3 categories—\"quick\", \"medium\", \"difficult\". You don’t need to recreate and retrain a model from scratch! You can just start from the intermediate features of your previous model, since you have access to them. Like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/updated_ticket_classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the `Model` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model building pattern you should know about is the most advanced one: **Model subclassing**. You’ve already learned in chapter 3 how to subclass the `Layer` class to create custom layers. Subclassing `Model` is pretty similar:\n",
    "\n",
    "- In the init method, define the layers the model will use.\n",
    "- In the call method, define the forward pass of the model, reusing the layers previously created.\n",
    "- Instantiate your subclass and call it on data to create its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at a simple example: we will reimplement the customer support ticket management model using a `Model` subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        # define all the layers in the model but the input\n",
    "        # note: you do not call the layers on anything! That is the job of the call method (forward pass)\n",
    "        super().__init__()  # call the super constructor\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # define the forward pass through the model\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "print(model.weights)  # no weights yet!\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compile and train a `Model` subclass just like a `Sequential` or `Functional` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 36ms/step - loss: 7.7848 - output_1_loss: 0.3246 - output_2_loss: 7.4602 - output_1_mean_absolute_error: 0.4888 - output_2_accuracy: 0.2508\n",
      "40/40 [==============================] - 2s 36ms/step - loss: 3.4584 - output_1_loss: 0.3289 - output_2_loss: 3.1295 - output_1_mean_absolute_error: 0.4927 - output_2_accuracy: 0.5891\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model subclassing workflow is the most flexible way to build a model: it **enables you to build models that cannot be expressed as directed acyclic graphs of layer**—imagine, for instance, a model where the call() method uses layers inside a for loop, or even calls them recursively. Anything is possible—you’re in charge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer dense_28 is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18580/3981240663.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixing_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36minput\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2042\u001b[0m     \"\"\"\n\u001b[0;32m   2043\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m       raise AttributeError('Layer ' + self.name +\n\u001b[0m\u001b[0;32m   2045\u001b[0m                            ' is not connected, no input to return.')\n\u001b[0;32m   2046\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_tensors'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer dense_28 is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "model.mixing_layer.input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: what subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, because the way layers are connected to each other is hidden inside the body of the `call()` method, you cannot access that information. Calling `summary()` will **not display layer connectivity**, and you **cannot plot the model** topology via `plot_model()`. Likewise, if you have a subclassed model, you **cannot access the nodes of the graph** of layers to do feature extraction—because there is simply no graph. Once the model is instantiated, its forward pass becomes a complete blackbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crucially, choosing one of these patterns—the Sequential model, the Functional API, Model subclassing—does not lock you out of the others. **All models in the Keras API can smoothly interoperate with each other**, whether they’re Sequential models, Functional models, or subclassed models written from scratch. They’re all part of the same spectrum of workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)  # here we use our own Model subclass!\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier  # here we use a Functional model that was defined outside!\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the Functional API provides you with a pretty good trade-off between easy-of-use and flexibility. It also gives you direct access to layer connectivity, which is **very powerful for use cases such as model plotting or feature extraction**. If you can use the Functional API—that is, if your model can be expressed as a **directed acyclic graph of layers**—I recommend using it over model subclassing.\n",
    "\n",
    "Going forward, all examples in this book will use the Functional API—simply because all of the models we will work with are expressible as graphs of layers. We will, however, make frequent use of subclassed layers. In general, using Functional models that include subclassed layers provides the best of both world: high development flexibility while retaining the advantages of the Functional API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are already familiar with the `compile()`, `fit()`, `evaluate()`, `predict()` workflow. As a reminder, it looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()` / `fit()` / `evaluate()` / `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2933 - accuracy: 0.9128 - val_loss: 0.1546 - val_accuracy: 0.9541\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1640 - accuracy: 0.9544 - val_loss: 0.1217 - val_accuracy: 0.9680\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1374 - accuracy: 0.9632 - val_loss: 0.1160 - val_accuracy: 0.9719\n",
      "313/313 [==============================] - 0s 891us/step - loss: 0.1045 - accuracy: 0.9729\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways you can customize this simple workflow:\n",
    "\n",
    "- Providing your own custom metrics\n",
    "- Passing **callbacks** to the `fit()` method to schedule actions to be taken at specific points during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used metrics for classification and regression are already part of the built-in `keras.metrics` module—most of the time, that’s what you will use. But if you’re doing anything out of the ordinary, you will need to be able to write your own metrics. It’s simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here’s a simple custom metric that measures the Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "    \n",
    "    # You use the result() method to return the current value of the metric:\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras callbacks API will help you transform your call to `model.fit()` from a paper airplane into a smart, autonomous drone that can self-introspect and dynamically take action.\n",
    "\n",
    "A callback is an object (a class instance implementing specific methods) that is passed to the model in the call to `fit()` and that is called by the model at various points during training. **It has access to all the available data about the state of the model and its performance**, and it can take action: **interrupt training, save a model, load a different weight set, or otherwise alter the state of the model**.\n",
    "\n",
    "Here are some examples of ways you can use callbacks:\n",
    "\n",
    "- **Model checkpointing** — Saving the current state of the model at different points during training.\n",
    "- **Early stopping** — Interrupting training when the validation loss is no longer improving (and of course, saving the best model obtained during training).\n",
    "- **Dynamically adjusting the value of certain parameters during training** — Such as the learning rate of the optimizer.\n",
    "- **Logging training and validation metrics during training**, or visualizing the representations learned by the model as they’re updated — The `fit()` progress bar that you’re familiar with is in fact a callback!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The `EarlyStopping` and `ModelCheckpoint` callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `EarlyStopping` callback interrupts training once a target metric being monitored has stopped improving for a fixed number of epochs. For instance, this callback allows you to interrupt training as soon as you start overfitting, thus avoiding having to retrain your model for a smaller number of epochs. This callback is typically used in combination with `ModelCheckpoint`, which lets you continually save the model during training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2928 - accuracy: 0.9141 - val_loss: 0.1561 - val_accuracy: 0.9569\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1661 - accuracy: 0.9528 - val_loss: 0.1172 - val_accuracy: 0.9675\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1378 - accuracy: 0.9622 - val_loss: 0.1137 - val_accuracy: 0.9702\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1240 - accuracy: 0.9677 - val_loss: 0.1065 - val_accuracy: 0.9753\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1189 - accuracy: 0.9706 - val_loss: 0.1081 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16540f36df0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks are passed to the model via the callbacks argument in fit(), \n",
    "# which takes a list of callbacks. \n",
    "# You can pass any number of callbacks.\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(  # Interrupts training when improvement stops\n",
    "        monitor=\"val_accuracy\",  # Monitors the model’s validation accuracy\n",
    "        patience=1,  # Interrupts training when accuracy has stopped improving for more than one epoch (that is, two epochs)\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(  # Saves the current weights after every epoch\n",
    "        filepath=\"checkpoint_path.keras\",  # Path to the destination model file\n",
    "        monitor=\"val_loss\",  # These two arguments mean you won’t overwrite the model file unless val_loss has improved, which allows you to keep the best model seen during training.\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=50,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can always save models manually after training as well—just call `model.save('my_checkpoint_path')`. To reload the model you’ve saved, just use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(train_images[0].reshape(1, 784))), train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks are implemented by subclassing the class `keras.callbacks.Callback`. You can then implement any number of the following transparently-named methods, which are called at various points during training:\n",
    "\n",
    "```\n",
    "on_epoch_begin(epoch, logs)\n",
    "on_epoch_end(epoch, logs)\n",
    "on_batch_begin(batch, logs)\n",
    "on_batch_end(batch, logs)\n",
    "on_train_begin(logs)\n",
    "on_train_end(logs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a simple example saving a list of per-batch loss values during training, and saves a graph of these values at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2908 - accuracy: 0.9147 - val_loss: 0.1432 - val_accuracy: 0.9589\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1640 - accuracy: 0.9544 - val_loss: 0.1291 - val_accuracy: 0.9646\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1375 - accuracy: 0.9632 - val_loss: 0.1118 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1247 - accuracy: 0.9675 - val_loss: 0.1127 - val_accuracy: 0.9742\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1160 - accuracy: 0.9698 - val_loss: 0.1119 - val_accuracy: 0.9760\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1113 - accuracy: 0.9732 - val_loss: 0.1090 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1029 - accuracy: 0.9756 - val_loss: 0.1255 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1031 - accuracy: 0.9759 - val_loss: 0.1124 - val_accuracy: 0.9794\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0983 - accuracy: 0.9780 - val_loss: 0.1081 - val_accuracy: 0.9806\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0910 - accuracy: 0.9792 - val_loss: 0.1200 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1654990d520>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorBoard** is a browser-based application that you can run locally. It’s the best way to monitor everything that goes on inside your model during training. With TensorBoard, you can:\n",
    "\n",
    "- Visually monitor metrics during training\n",
    "- Visualize your model architecture \n",
    "- Visualize histograms of activations and gradients\n",
    "- Explore embeddings in 3D\n",
    "\n",
    "![](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/the_loop_of_progress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to use TensorBoard with a Keras model and the fit method is the `keras.callbacks.TensorBoard` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2934 - accuracy: 0.9130 - val_loss: 0.1493 - val_accuracy: 0.9567\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1612 - accuracy: 0.9545 - val_loss: 0.1217 - val_accuracy: 0.9665\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1411 - accuracy: 0.9623 - val_loss: 0.1168 - val_accuracy: 0.9714\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1238 - accuracy: 0.9679 - val_loss: 0.1086 - val_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1154 - accuracy: 0.9710 - val_loss: 0.1100 - val_accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1088 - accuracy: 0.9733 - val_loss: 0.1121 - val_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1089 - accuracy: 0.9744 - val_loss: 0.1129 - val_accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1005 - accuracy: 0.9770 - val_loss: 0.1156 - val_accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1009 - accuracy: 0.9769 - val_loss: 0.1042 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0926 - accuracy: 0.9787 - val_loss: 0.1137 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16548ee1580>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"tensorboard_log\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model starts running, it will write logs at the target location. If you are running you Python script on a local machine, you can then launch the local TensorBoard server using the following command (note that the tensorboard executable should be already available if you have installed TensorFlow via pip; if not, you can install TensorBoard manually via `pip install tensorboard`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5536), started 0:05:08 ago. (Use '!kill 5536' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3ea7ddae9e8d0fc8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3ea7ddae9e8d0fc8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tensorboard_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with `tf.function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging `fit()` with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Chapter summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keras offers a spectrum of different workflows, based on the principle of progressive disclosure of complexity. They all smoothly interoperate together.\n",
    "- You can build models via the `Sequential` class, via the `Functional` API, or by subclassing the `Model` class. Most of the time, you’ll be using the Functional API.\n",
    "- The simplest way to train & evaluate a model in via the default `fit()` & `evaluate()` methods.\n",
    "- Keras **callbacks** provide a simple way to monitor models during your call to `fit()` and automatically take action based on the state of the model.\n",
    "- You can also fully take control of what `fit()` does by overriding the `train_step()` method.\n",
    "- Beyond `fit()`, you can also write your own training loops entirely from scratch. This is useful for researchers implementing brand new training algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
